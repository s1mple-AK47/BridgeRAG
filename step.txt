阶段一：环境与地基 (Foundation & Infrastructure)

docker-compose.yml: 编写此文件，用 docker-compose up -d 一键启动Neo4j, Milvus和MinIO。
.env 和 configs/config.yaml: 定义基础配置，如数据库端口和密码。
bridgerag/config.py: 编写代码加载配置。
requirements.txt: 列出所有初始依赖包。
notebooks/01_test_db_connections.ipynb: 使用Notebook验证所有数据库服务都能成功连接。

阶段二：核心服务封装 (Core Service Abstraction)

bridgerag/database/*.py: 将Notebook中的连接代码，封装成可重用的数据库连接类。
bridgerag/core/*.py: 编写LLM和Embedding客户端，用于和vLLM服务进行交互。

阶段三：可扩展的离线数据处理管道 (The Scalable Offline Pipeline)
目标：构建一个能处理海量文档、支持并行处理的健壮数据管道。

1.  bridgerag/offline/pipeline.py: 设计管道编排器。使用任务队列（如Celery）来管理和调度任务，实现文档的并行处理和任务链管理。
2.  bridgerag/offline/steps/build_partitions.py: 实现分区图谱构建的核心任务。接收单个文档，完成实体抽取、关系抽取、实体合并、元数据生成（摘要、实体清单）、实体嵌入等操作，并将结果存入Neo4j。
3.  bridgerag/offline/steps/link_entities.py: 实现跨文档实体链接的核心任务。在所有文档处理完毕后启动，并行地对候选实体对进行混合评分，并将合格的`SAME_AS`关系写入Neo4j。
4.  bridgerag/utils/text_processing.py: 提供通用的文本处理工具，如文本分块等。
5.  scripts/run_offline_pipeline.py: 编写管道的启动脚本，提供命令行接口，用于触发整个离线数据处理流程。

阶段四：高并发在线推理服务 (The High-Concurrency Online Service)
目标：构建一个基于FastAPI的、健壮且可扩展的在线API，实现您论文中定义的复杂、迭代式检索与生成策略。

1.  bridgerag/online/schemas.py: (无变化) 使用Pydantic定义严格的API数据模型，包括查询请求、最终答案、中间步骤和错误响应。
2.  bridgerag/online/main.py: (无变化) API入口文件。负责定义 /query 路由，通过依赖注入编排核心服务，并设置全局异常处理器。
3.  bridgerag/online/services/routing_service.py: 实现 **第一阶段：候选文档检索**。
    *   职责: 从海量文档中筛选出 Top-10 最相关的候选文档。
    *   实现:
        *   问题实体提取: 调用LLM从用户问题中提取命名实体。
        *   双路召回:
            *   实体匹配: 在Neo4j中根据实体共现频率召回文档。
            *   语义匹配: 在Milvus中根据文档摘要与问题的向量相似度召回文档。
        *   排序融合: 使用倒数排序融合 (RRF) 算法合并两路召回结果，得到最终候选列表。
4.  bridgerag/online/services/reasoning_service.py: 实现 **第二阶段与第四阶段：检索规划与迭代推理循环**。
    *   职责: 作为推理流程的“大脑”，编排整个迭代式问答循环。
    *   实现:
        *   检索规划 (LLM Planner): 接收候选文档列表，调用LLM生成结构化的检索计划 (`main`文档和`assist`文档及实体)。
        *   迭代控制: 管理一个最多三轮的循环。
        *   任务分发: 在每一轮循环中，调用 `retrieval_service` 执行检索计划，然后调用 `synthesis_service` 尝试生成答案。
        *   状态管理: 根据生成结果（是答案还是子问题），决定是结束循环还是带着新问题和上下文开始下一轮。
5.  bridgerag/online/services/retrieval_service.py: 实现 **第三阶段：执行计划与证据收集**。
    *   职责: 根据 `reasoning_service` 传来的检索计划，精准地从数据库中提取证据。
    *   实现:
        *   主文档处理 (鲁棒性增强):
            *   **LLM实体选择**: 针对每个主文档，将用户问题、文档摘要和该文档内的所有实体列表一同送入LLM，由LLM判断并挑选出与问题最相关的实体进行后续查询，解决实体名称不匹配问题。
            *   **信息提取**: 获取最相关的文本`chunks`（向量检索），以及被LLM选中的实体的摘要。
            *   **`SAME_AS`扩展**: 对被选中的实体执行`SAME_AS`关系扩展，获取并筛选关联实体的摘要。
        *   辅助文档处理: (无变化) 仅获取计划中指定的实体摘要。
6.  bridgerag/online/services/synthesis_service.py: 实现 **第四阶段（部分）：答案合成或子问题生成**。
    *   职责: 将所有收集到的证据整合成最终答案，或判断信息不足并提出下一步行动。
    *   实现:
        *   调用LLM，并提供包含所有证据的Prompt。
        *   指示LLM：如果信息充足，则生成最终答案；如果信息不足，则生成一个**新的子问题**和**当前信息的摘要**。
7.  在`main.py`的 `/query` 端点中，主要调用 `reasoning_service` 来启动整个流程，由它在内部完成对其他服务的调用和编排。

阶段五：工业化与生态系统构建 (Industrialization & Ecosystem)
目标：在核心功能之上，构建一个健壮、可靠、可观测的生产级系统。

1.  运维与可靠性 (DevOps / MLOps):
    *   CI/CD: 建立自动化测试、构建和部署的流水线 (如 GitHub Actions)。
    *   容器编排: 使用 Kubernetes (K8s) 管理生产环境中的容器，实现自动扩展和故障恢复。
    *   监控与告警: 使用 Prometheus, Grafana, Loki 等工具，建立完整的监控、日志和告警体系。

2.  数据与模型生命周期管理:
    *   实验跟踪: 使用 MLflow 或 W&B 记录模型实验的参数、指标和产物。
    *   数据与模型版本控制: 使用 DVC 等工具管理数据集和大型模型文件。
    *   模型注册表: 建立中心化的模型仓库，管理模型的不同版本和部署阶段。

3.  健壮性与质量保障:
    *   自动化测试: 编写全面的集成测试和端到端 (E2E) 测试。
    *   RAG评估框架: 使用 Ragas, TruLens 等框架，建立标准化的评估流水线，量化答案质量。

4.  安全与治理:
    *   密钥管理: 使用 Vault 或云厂商的密钥管理服务来存储数据库密码等敏感信息。
    *   API网关: 在服务前设置统一的API网关，处理认证、限流和缓存等通用需求。

5.  文档与知识沉淀:
    *   自动化文档: 使用 Sphinx 或 MkDocs 自动从代码注释生成项目文档网站。
    *   架构决策记录 (ADR): 为项目中的重要技术决策编写文档，记录原因和背景。





附录：工业级项目核心特征
这部分内容是我们项目的“代码宪法”，总结了一个项目从“能用”到“卓越”所需遵循的核心原则。

---

### 1. 鲁棒性与容错 (Robustness & Fault Tolerance)
**理念**: 你的代码一定会出错，但系统不能因此崩溃。架构设计必须假设失败是常态。

*   **全面的错误处理**:
    *   **拒绝 `print(exception)`**: 绝不能简单地打印异常然后继续运行。
    *   **使用特定的 `try...except` 块**: 捕获你预料到的具体异常（如 `ConnectionError`, `FileNotFoundError`, `KeyError`），并进行处理。对无法预料的异常，用一个通用的 `except Exception` 来捕获，但主要目的是记录日志并返回一个通用的服务器错误，而不是让程序崩溃。
    *   **在本项目中的体现**: 在 `online/services/*.py` 中，任何对数据库或LLM的调用都必须包裹在 `try...except` 块里。如果数据库查询超时，API应该向用户返回 `HTTP 503 Service Unavailable`，而不是无响应或崩溃。

*   **重试机制 (Retry Logic)**:
    *   对于网络请求（调用vLLM、连接数据库），失败是常态。必须实现重试逻辑，最好是带指数退避（Exponential Backoff）的策略，避免在对方服务宕机时发起DDoS攻击。

*   **优雅降级 (Graceful Degradation)**:
    *   如果某个非核心功能失败（比如在实体链接时，某个辅助评分模型加载失败），系统能否降级到只使用主要评分模型来完成链接，而不是整个流程失败？
    *   **在本项目中的体现**: 在 `offline/pipeline.py` 中，如果处理单个文档失败，整个管道应该记录该文档的错误，然后继续处理下一个文档，而不是全盘终止。

---

### 2. 可维护性与可读性 (Maintainability & Readability)
**理念**: 代码是写给人读的，只是顺便让机器执行。未来的你（或你的同事）会感谢你。

*   **单一职责与模块化**:
    *   每个函数、每个类、每个模块只做一件事情。
    *   **在本项目中的体现**: 我们的 `bridgerag` 包结构就是模块化的体现：`database` 只管数据库，`core` 只管模型调用，`utils` 只管通用工具。这种清晰的划分使得代码易于理解和定位。

*   **清晰的命名与文档**:
    *   变量名、函数名、类名要能准确描述其用途（`process_documents` 好于 `proc_docs`）。
    *   注释应该解释“为什么”这么做，而不是“是什么”。代码本身应该能解释“是什么”。
    *   **在本项目中的体现**: 我们为所有核心类和函数都编写了详尽的中文文档字符串（docstring）。

*   **配置与代码分离**:
    *   避免魔法数字/字符串。把配置项（如重试次数`3`，模型名称`"nomic-embed-text-v1"`）统一放到 `configs/config.yaml` 中，而不是硬编码在代码里。
    *   **在本项目中的体现**: `bridgerag/config.py` 就是我们项目的配置中心，它让我们可以不修改任何业务代码就调整系统参数。

*   **严格的接口定义**:
    *   函数和API的输入、输出都有严格的类型定义和数据校验。
    *   **在本项目中的体现**: 我们使用 Pydantic 来定义API的 `schemas`，并为所有Python函数添加了 `type hints`。

---

### 3. 性能与效率 (Performance & Efficiency)
**理念**: 代码不仅要完成任务，还要在可接受的时间和资源内完成。

*   **批量操作 (Batching)**:
    *   对于离线管道，向数据库或AI模型发送数据时，使用批量操作远比单条操作高效。
    *   **在本项目中的体现**: 在离线管道中，当为实体生成 `entity_embedding` 时，应该批量将实体描述发送给 `EmbeddingClient`，而不是一次一个。

*   **数据库优化**:
    *   **避免N+1查询**: 不要在一个循环里反复查询数据库。尽可能一次性获取所有需要的数据。
    *   **使用索引**: 在Neo4j和Milvus中为经常被查询的属性创建索引。这是提升查询速度最立竿见影的方法。
    *   **在本项目中的体现**: 需要为Neo4j中的 `Entity` 节点的 `name` 属性创建索引，因为我们会频繁地根据名称查找实体。

*   **高效的内存使用**:
    *   在处理大文档或大批量数据时，注意不要将所有东西一次性加载到内存中。使用生成器（`yield`）或流式处理。

---

### 4. 可扩展性与并发 (Scalability & Concurrency)
**理念**: 系统应该能通过增加资源（垂直扩展）或增加机器（水平扩展）来处理增长的负载。

*   **无状态服务 (Stateless Services)**:
    *   这是实现水平扩展的黄金法则。你的在线FastAPI服务绝对不能在内存中保存任何与特定用户或请求相关的状态。所有状态都必须存储在外部数据库（Neo4j, Milvus, Redis等）中。
    *   **在本项目中的体现**: 我们的 FastAPI 应用被设计为完全无状态的，这使得我们可以简单地启动多个服务实例，用一个负载均衡器将请求分发给它们。

*   **异步化与解耦**:
    *   **在线服务**: FastAPI天生为异步而生。我们应该在所有API路径函数前加上 `async def`，并在所有I/O操作（数据库查询、vLLM调用）前使用 `await`。这能让单个进程高效处理成百上千的并发连接。
    *   **离线管道**: 对于耗时且不需要立即返回结果的任务，使用任务队列（如Celery）来处理。
    *   **在本项目中的体现**: `online` 部分利用FastAPI的异步特性提高并发能力，`offline` 部分利用Celery实现大规模并行处理。

---

### 5. 安全性 (Security)
**理念**: 时刻假设你的系统正被攻击。

*   **管理好密钥**:
    *   你的 `.env` 文件是第一道防线。在生产环境中，使用更专业的密钥管理服务（如HashiCorp Vault或云服务商提供的KMS）。

*   **输入验证与注入防护**:
    *   **输入验证**: 永远不要相信用户的输入。FastAPI结合Pydantic `schemas`为我们做了大部分工作。
    *   **数据库注入**: 使用参数化查询，绝不能用f-string拼接SQL或Cypher语句。`neo4j-driver` 等库默认就支持参数化。
    *   **Prompt注入**: 对用户的输入进行清洗和检查，或者在Prompt中明确指示LLM忽略用户输入中可能包含的指令。